spark.hadoop.fs.s3a.endpoint=http://minio:9000
spark.hadoop.fs.s3a.access.key=admin
spark.hadoop.fs.s3a.secret.key=admin12345
spark.hadoop.fs.s3a.path.style.access=true
spark.hadoop.fs.s3a.connection.ssl.enabled=false
spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
spark.hadoop.fs.s3a.connection.timeout=60000
spark.hadoop.fs.s3a.connection.establish.timeout=5000
spark.hadoop.fs.s3a.connection.request.timeout=60000
spark.hadoop.fs.s3a.connection.part.upload.timeout=60000
spark.hadoop.fs.s3a.connection.idle.time=60000
spark.hadoop.fs.s3a.threads.keepalivetime=60000
spark.hadoop.fs.s3a.vectored.read.min.seek.size=131072
spark.hadoop.fs.s3a.vectored.read.max.merged.size=2097152
spark.hadoop.fs.s3a.impl.disable.cache=true
spark.hadoop.fs.s3a.fast.upload=true
spark.hadoop.fs.s3a.multipart.size=104857600
spark.hadoop.fs.s3a.threads.max=10
spark.hadoop.fs.s3a.connection.maximum=15
spark.hadoop.fs.s3a.attempts.maximum=3
spark.hadoop.fs.s3a.retry.limit=5
spark.hadoop.fs.s3a.retry.interval=500
spark.hadoop.fs.s3a.socket.recv.buffer=65536
spark.hadoop.fs.s3a.socket.send.buffer=65536
spark.hadoop.fs.s3a.multipart.purge.age=86400

spark.sql.adaptive.coalescePartitions.enabled=false
spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions

spark.sql.catalog.local=org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.local.type=nessie
spark.sql.catalog.local.uri=http://nessie:19120/api/v2
spark.sql.catalog.local.warehouse=s3a://lakehouse/warehouse

spark.jars=/opt/spark/jars/hadoop-aws-3.3.4.jar, \
/opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar, \
/opt/spark/jars/ojdbc11.jar, \
/opt/spark/jars/iceberg-aws-bundle-1.9.2.jar, \
/opt/spark/jars/iceberg-nessie-1.9.2.jar
spark.driver.extraClassPath=/opt/spark/*
spark.executor.extraClassPath=/opt/spark/jars/*
