services:
  postgres-nessie:
    image: postgres:17
    env_file:
      - .env
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres-nessie-volume:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD", "pg_isready", "-U", "${POSTGRES_USER}" ]
      interval: 10s
      retries: 5
      start_period: 5s
    restart: always

  nessie:
    image: ghcr.io/projectnessie/nessie:latest
    container_name: nessie
    environment:
      QUARKUS_HTTP_PORT: 19120
      QUARKUS_DATASOURCE_JDBC_URL: ${QUARKUS_DATASOURCE_JDBC_URL}
      QUARKUS_DATASOURCE_USERNAME: ${QUARKUS_DATASOURCE_USERNAME}
      QUARKUS_DATASOURCE_PASSWORD: ${QUARKUS_DATASOURCE_PASSWORD}
      NESSIE_VERSION_STORE_TYPE: ${NESSIE_VERSION_STORE_TYPE}
#      QUARKUS_DATASOURCE_DB_KIND: ${QUARKUS_DATASOURCE_DB_KIND}
    ports:
      - "19120:19120"
    depends_on:
      postgres-nessie:
        condition: service_healthy
#    healthcheck:
#      test: [ "CMD", "wget", "-qO-", "http://localhost:19120/api/v2/config" ]
#      interval: 10s
#      timeout: 3s
#      retries: 10
#      start_period: 10s

  trino:
    image: trinodb/trino:463   # ổn định với JDK17
    container_name: trino
    env_file:
      - .env
    ports:
      - "8088:8080"
    volumes:
      - ./trino/etc:/etc/trino
    depends_on:
      - minio

  minio:
    image: quay.io/minio/minio:RELEASE.2025-07-23T15-54-02Z
    container_name: my_minio
    env_file:
      - .env
    ports:
      - "9000:9000"  # S3 API
      - "9001:9001"  # Web console
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    volumes:
      - ./data:/data
    command: server /data --console-address ":9001"
    restart: always

  spark-master:
    image: bitnami/spark:3.5.6
    build:
      context: .
      dockerfile: Dockerfile
    env_file:
      - .env
    mem_limit: "2g"
    memswap_limit: "2g"
    volumes:
      - ./spark/conf/log4j2.properties:/opt/bitnami/spark/conf/log4j2.properties:ro
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
    ports:
      - "7077:7077"      # Spark master RPC
      - "18080:8080"

  spark-worker-1:
    image: bitnami/spark:3.5.6
    build:
      context: .
      dockerfile: Dockerfile
    env_file:
      - .env
    mem_limit: "8g"
    memswap_limit: "8g"
    volumes:
      - ./spark/conf/log4j2.properties:/opt/bitnami/spark/conf/log4j2.properties:ro
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_WEBUI_PORT=8082
      - SPARK_WORKER_MEMORY=4g
      - SPARK_DAEMON_MEMORY=1g
    depends_on:
      - spark-master
    ports:
      - "8082:8082"

  spark-worker-2:
    image: bitnami/spark:3.5.6
    build:
      context: .
      dockerfile: Dockerfile
    env_file:
      - .env
    mem_limit: "8g"
    memswap_limit: "8g"
    volumes:
      - ./spark/conf/log4j2.properties:/opt/bitnami/spark/conf/log4j2.properties:ro
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_WEBUI_PORT=8083
      - SPARK_WORKER_MEMORY=4g
      - SPARK_DAEMON_MEMORY=1g
    depends_on:
      - spark-master
    ports:
      - "8083:8083"

#  kafka:
#    image: confluentinc/cp-kafka:7.5.0
#    depends_on:
#      - zookeeper
#    ports:
#      - "9092:9092"
#    environment:
#      KAFKA_BROKER_ID: 1
#      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
#      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
#      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
#
#  zookeeper:
#    image: confluentinc/cp-zookeeper:7.5.0
#    ports:
#      - "2181:2181"
#    environment:
#      ZOOKEEPER_CLIENT_PORT: 2181
#      ZOOKEEPER_TICK_TIME: 2000
#
#  schema-registry:
#    image: confluentinc/cp-schema-registry:7.5.0
#    depends_on:
#      - kafka
#    ports:
#      - "8081:8081"
#    environment:
#      SCHEMA_REGISTRY_HOST_NAME: schema-registry
#      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka:9092

networks:
  default:
    external: true
    name: lakehouse_network

volumes:
  postgres-nessie-volume: